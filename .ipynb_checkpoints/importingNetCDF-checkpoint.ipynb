{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33851ee6-e33b-40fa-a97e-935eb022684e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "import requests as req\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/inunezfe/Documents/netCD4\")\n",
    "import state_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f4aa4dd-5887-4060-9596-1ec8f316028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will download the data using the urls from the isimip webpage. \n",
    "\n",
    "def get__isimip_data(path):\n",
    "    #The Url + path find in the ISIMIP web page\n",
    "    url = 'https://files.isimip.org/' + path\n",
    "    #Extract the name of the file\n",
    "    file_name = path.split('/')[-1]\n",
    "    # Get the file\n",
    "    with req.get(url, stream = True) as response:\n",
    "        # Get the status code\n",
    "        if response.status_code == 200:\n",
    "            print('Success!')\n",
    "        elif response.status_code == 404:\n",
    "            print('Not Found.')\n",
    "        #Write the response in a file.\n",
    "        with open(file_name, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "                \n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0603894c-f490-430f-b822-1e2d90116361",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#### Loads MERRA netcdf file and important variables ####\\n# Note: operates over one day of data based on the daily nature of each MERRA file # \\ndef organize_MERRAvar(MERRA_file_path):\\n    data = Dataset(MERRA_file_path)\\n    \\n    ### Extracts location variables and other important variables from \"data\" ###\\n    lons = data.variables[\\'lon\\'][:]\\n    lats = data.variables[\\'lat\\'][:]\\n    hurs = data.variables[\\'hurs\\'][:,:,:]\\n    \\n    # Arturo se la come\\n    \\n    ### print the variables saved on the dataset\\n    print(data.variables)\\n    \\n    ### Defines time variable ###\\n    \\n    time = np.arange(1,hurs.shape[0]+1)\\n    \\n    ### Consolidates time, location, and variables of interest (i.e. temp) into one dataframe ###\\n    names = [\\'t\\',\\'y\\',\\'x\\']\\n    index = pd.MultiIndex.from_product([time,lats,lons], names=names)\\n    df = pd.DataFrame({\\'hurs\\': hurs.flatten()}, index=index)[\\'hurs\\']\\n    df.index.names = [\\'time\\', \\'lats\\', \\'lons\\']\\n    df = df.reset_index(level=[\\'time\\', \\'lats\\', \\'lons\\'])\\n    df = pd.DataFrame.to_numpy(df)\\n   \\n\\n    # manage data for the state of indiana here\\n    \\n   \\n    \\n    ### coordinates from locations are in the following order: W, E, S, N\\n    W, E, S, N = state_locations.get_state_loc(\\'IN\\')\\n    \\n    ### create matrix for the coordinates from the state lat = vertical (north to south), lon = horizontal (west to east)\\n    \\n        \\n    \\n    # Adds temperature columns (one for each timestamp) # \\n    nlons = lons.shape[0]\\n    nlats = lats.shape[0]\\n    blockt0 = nlons*nlats\\n    \\n    \\n    \\n    # Create temp matrix with the columns for each time + appends to df_new #\\n    df_new = df[0:blockt0,1:3]\\n    for count, value in enumerate(time,start=0):    \\n        t_append = df[(count)*blockt0:(count+1)*blockt0,3]\\n        df_new = np.column_stack((df_new,t_append))\\n    \\n    \\n    \\n    return df_new, time, lats, lons, nlons '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#### Loads MERRA netcdf file and important variables ####\n",
    "# Note: operates over one day of data based on the daily nature of each MERRA file # \n",
    "def organize_MERRAvar(MERRA_file_path):\n",
    "    data = Dataset(MERRA_file_path)\n",
    "    \n",
    "    ### Extracts location variables and other important variables from \"data\" ###\n",
    "    lons = data.variables['lon'][:]\n",
    "    lats = data.variables['lat'][:]\n",
    "    hurs = data.variables['hurs'][:,:,:]\n",
    "    \n",
    "    # Arturo se la come\n",
    "    \n",
    "    ### print the variables saved on the dataset\n",
    "    print(data.variables)\n",
    "    \n",
    "    ### Defines time variable ###\n",
    "    \n",
    "    time = np.arange(1,hurs.shape[0]+1)\n",
    "    \n",
    "    ### Consolidates time, location, and variables of interest (i.e. temp) into one dataframe ###\n",
    "    names = ['t','y','x']\n",
    "    index = pd.MultiIndex.from_product([time,lats,lons], names=names)\n",
    "    df = pd.DataFrame({'hurs': hurs.flatten()}, index=index)['hurs']\n",
    "    df.index.names = ['time', 'lats', 'lons']\n",
    "    df = df.reset_index(level=['time', 'lats', 'lons'])\n",
    "    df = pd.DataFrame.to_numpy(df)\n",
    "   \n",
    "\n",
    "    # manage data for the state of indiana here\n",
    "    \n",
    "   \n",
    "    \n",
    "    ### coordinates from locations are in the following order: W, E, S, N\n",
    "    W, E, S, N = state_locations.get_state_loc('IN')\n",
    "    \n",
    "    ### create matrix for the coordinates from the state lat = vertical (north to south), lon = horizontal (west to east)\n",
    "    \n",
    "        \n",
    "    \n",
    "    # Adds temperature columns (one for each timestamp) # \n",
    "    nlons = lons.shape[0]\n",
    "    nlats = lats.shape[0]\n",
    "    blockt0 = nlons*nlats\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create temp matrix with the columns for each time + appends to df_new #\n",
    "    df_new = df[0:blockt0,1:3]\n",
    "    for count, value in enumerate(time,start=0):    \n",
    "        t_append = df[(count)*blockt0:(count+1)*blockt0,3]\n",
    "        df_new = np.column_stack((df_new,t_append))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_new, time, lats, lons, nlons '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ff5ae-0301-4a7a-b971-646a9d6802d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Just the first path to test \n",
    "'''paths = [ 'ISIMIP2b/SecondaryInputData/GCM_atmosphere/biascorrected/global/rcp45/HadGEM2-ES/hurs_day_HadGEM2-ES_rcp45_r1i1p1_EWEMBI_20060101-20101231.nc4']'''\n",
    "\n",
    "\n",
    "# All the paths\n",
    "paths = [ 'ISIMIP2b/SecondaryInputData/GCM_atmosphere/biascorrected/global/rcp45/HadGEM2-ES/hurs_day_HadGEM2-ES_rcp45_r1i1p1_EWEMBI_20060101-20101231.nc4'\n",
    "         ,'ISIMIP2b/SecondaryInputData/GCM_atmosphere/biascorrected/global/rcp45/HadGEM2-ES/hurs_day_HadGEM2-ES_rcp45_r1i1p1_EWEMBI_20110101-20201231.nc4'\n",
    "         ,'ISIMIP2b/SecondaryInputData/GCM_atmosphere/biascorrected/global/rcp45/HadGEM2-ES/hurs_day_HadGEM2-ES_rcp45_r1i1p1_EWEMBI_20210101-20301231.nc4'\n",
    "         ,'ISIMIP2b/SecondaryInputData/GCM_atmosphere/biascorrected/global/rcp45/HadGEM2-ES/hurs_day_HadGEM2-ES_rcp45_r1i1p1_EWEMBI_20310101-20401231.nc4'\n",
    "         ,'ISIMIP2b/SecondaryInputData/GCM_atmosphere/biascorrected/global/rcp45/HadGEM2-ES/hurs_day_HadGEM2-ES_rcp45_r1i1p1_EWEMBI_20410101-20501231.nc4']\n",
    "\n",
    "\n",
    "# Get each nc4 file\n",
    "for path in paths:\n",
    "    # Open the netCDF4 file and read the data\n",
    "    get__isimip_data(path)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c001a-e2a2-4395-934d-eef1187b2a98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''organize_MERRAvar(\"/Users/inunezfe/Documents/hurs_day_HadGEM2-ES_rcp45_r1i1p1_EWEMBI_20060101-20101231.nc4\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8f08f-ff6e-4393-b294-2074e35c4759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
